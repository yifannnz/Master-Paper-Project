\chapter{文献综述}

\section{原子级高分辨图像质量提升算法概述}
随着图像采集设备的进步，TEM已经能够获得原子级分辨率的图像，提供原子位置、晶格参数和缺陷等信息。然而，图像质量常受仪器失真、噪声、设备漂移和电子束损伤等影响，导致信噪比低和图像模糊，影响原子结构分析。传统的线性滤波方法能减少高斯噪声，但在保留图像边缘方面效果不佳。为应对复杂噪声和细节保留问题，深度学习算法为图像去噪和超分辨率处理提供了保真性更强的解决方案。

\subsection{基于规则化方法的质量提升}
传统的图像去噪模型分为线性模型和非线性模型两类。在透射电子显微镜（TEM）图像去噪处理中，边缘细节的保留至关重要。然而，线性模型通常难以有效地保持图像的边缘特征，即将边缘作为图像中的不连续性时容易导致边缘模糊或扩散。相比之下，非线性模型在边缘保留方面表现更为优越，能够更好地维护图像的边缘细节结构。

Du\cite{du2015nonlinear}提出了一种非线性滤波算法，用于去除高分辨扫面透射电子显微镜图像中的噪声，能够有效抑制噪声的同时保留图像的细节信息，尤其在低剂量电子束下的噪声环境中表现良好。尽管该方法相比于传统的维纳滤波和高斯滤波方法表现出更高的稳定性和准确性，但由于其计算复杂度高，对噪声模型具有较强的依赖性，在复杂结构或高噪声条件下，可能会在细节保留和去噪平滑度之间产生权衡，限制其在实时和自动化应用中的潜力。

基于块匹配和3D滤波（Block-Matching and 3D Filtering，BM3D）算法\cite{dabov2007image}最初针对高斯噪声设计，通过将图像中的相似区域堆叠在三维域中，利用协作滤波去除噪声。高分辨透射电子显微镜在低剂量成像下，由于入射电子数目有限，电子计数过程的随机统计波动更加明显，从而产生与信号强度相关的泊松噪声，并在弱信号区域表现出更高的噪声占比。随后，Mevenkamp等\cite{mevenkamp2015poisson}改进了BM3D算法，将泊松噪声转化为高斯噪声并结合块匹配策略，提高了低剂量条件下的去噪效率和图像细节保留性。此外，该方法还针对周期性晶体结构提出了非局部块匹配策略，通过利用图像中的自相似性，以较低的计算成本实现有效去噪。

HRTEM filter插件是基于R. Kilaas的滤波方法\cite{kilaas1998optimal}开发的图像处理工具，专门用于HRTEM和扫描透射电子显微镜（Scanning transmission electron microscopy，STEM）数据中的无定形背景去噪。该插件自动应用Wiener滤波和自适应背景减法滤波，有效去除由无定形污染层带来的信号干扰。Wiener滤波在频域中优化信号，还原原始晶体结构信息，以最小均方误差准则实现对真实信号的最佳估计，该功能适用于从噪声和背景干扰中恢复精细的晶体特征；自适应背景减法滤波通过减去频域中平均背景来去除无定形层，适用于晶体与无定形信号强度相近的中频区域，在某些区域提供了更强的背景抑制能力。通过自动调整滤波参数，HRTEM filter能提高图像的信噪比和晶体结构细节，使原子排列和晶体缺陷的成像更清晰，从而提升后续数据分析的精确性和可靠性。
 
\subsection{基于深度学习方法的质量提升}
规则化方法在处理成像风格不同、噪声多样等条件下仍存在局限性，需要大量的参数调整与适配，且效果无法得到保证。近年来，随着人工智能和深度学习技术的发展，深度学习被应用于TEM数据处理，增强了去噪的泛化能力和鲁棒性\cite{lobato2024deep,kazimi2024self,mohan2022deep}。

AtomSegNet是专为TEM数据开发的深度学习模型，旨在实现高精度的原子分割，并提供了标准化数据集TEMImageNet\cite{lin2021temimagenet}。通过构建大规模的模拟数据集，涵盖了不同材料的原子分辨率ADF-STEM数据，引入多种噪声模型，以增强其对实验图像的适应性。AtomSegNet采用基于U-Net\cite{ronneberger2015u}的编码器-解码器结构，能有效去除背景噪声并保留原子级细节。实验表明，AtomSegNet在噪声较大的条件下，能够准确去除背景噪声，并在高噪声环境下仍然保留原子结构的清晰度。然而，模型训练高度依赖合成数据，实验图像中的非线性失真和电子源不稳定等因素可能影响其实际应用效果。

\begin{figure} [htb]
    \centering
    \includegraphics[width=0.8\textwidth]{images/chap2/1.png}
    \bicaption{基于深度学习的质量提升方法}{Deep learning-based quality enhancement methods}
    \label{fig:2-1}
\end{figure}

在AtomSegNet的基础上，Mohan等\cite{mohan2022deep}提出了一个仿真驱动的深度学习去噪框架（Simulation-based denoising，SBD），如图\figref{fig:2-1}(a)。该方法通过仿真生成大规模无噪声图像数据集并加入实验噪声，以解决实验数据缺乏的问题。SBD框架使用U-Net架构，捕捉图像中的周期性结构，显著提高了低信噪比数据的去噪效果。然而，即便是仿真驱动的方法仍然依赖大量的模拟数据，且难以避免与真实实验数据之间存在的差异。为进一步摆脱对任何形式“干净”图像的依赖，Crozier等\cite{crozier2025visualizing}提出了一种完全无监督的深度学习去噪框架，发表在2025年的Science期刊上。在高时间分辨率下，为了避免样品受损，需要使用低电子剂量，但低剂量会导致信噪比降低，遮蔽原子结构细节；连续帧拍摄导致噪声在时序上累积，影响对快速结构演化的观测，而普通图像叠加或滤波方法难以同时保持高分辨率和去噪能力。文章通过使用多帧时序上下文对每一帧进行还原，缓解了帧间运动模糊的问题。该框架的核心结构为盲点（Blind spot）卷积神经网络，即UDVD（Unsupervised deep video denoising）模型，如图\figref{fig:2-1}(b)。该模型结合了多帧信息和U-Net架构，在空间和时间维度上捕捉关键结构特征，在训练过程中排除了目标像素自身的值，仅利用其时空邻域像素信息进行估计，从而有效避免模型过拟合。该方法的提出解决了实验数据稀缺和仿真不准的问题，但该方法依赖于高质量的时间-空间一致性，且结构相对复杂，计算成本较高。因此，为了解决显微图像中间帧不一致与细节过度平滑等问题，He等\cite{he2025efficient}提出了一个支持实时处理的、适用于时序显微图像的零样本降噪与超分辨框架MDSR-Zero，如图\figref{fig:2-1}(c)。该方法完全不依赖干净图像或仿真数据，通过高效的在线训练策略（Efficient online training，EOT）显著加快了模型训练速度并提高了时间一致性。EOT利用前一帧的模型参数作为当前帧的初始化，保留跨帧结构信息，使得模型学习具有时间一致性的结构表征；引入指数滑动平均机制平滑更新模型权重，抑制帧间噪声波动，从而有效解决了帧间结构无法统一建模导致的原子区域边界模糊、细节流失、图像不稳定的问题。此外，作者还设计了一种面向超分辨率的自监督损失函数，在保持低分辨率重建准确性的同时，引导模型关注高频邻域信息，增强了图像细节恢复能力。该方法不仅在合成噪声和真实显微视频数据上表现出优越的去噪与结构保真性能，而且相比现有零样本方法训练效率提高近10倍，推理延迟低，可做到边采集边处理，展示出良好的实用性与扩展性。上述方法分别从数据生成方式、网络结构设计和训练策略上提供了不同的技术路线，适用于不同类型和需求的显微图像分析任务，为真实复杂场景下的后续任务提供了坚实的基础。然而，这些方法在提升特定场景下性能的同时，也暴露出一定的泛化能力局限性，主要体现在难以全面覆盖实验图像中多样化的噪声模式和结构变化，导致在跨设备、跨样本或复杂成像条件下的适应性和鲁棒性不足。

\subsection{基于生成对抗网络的图像质量提升}
生成对抗网络（Generative Adversarial Network，GAN）是Goodfellow\cite{goodfellow2014generative}等人在2014年提出的，通过对抗训练机制进行生成模型学习的框架，其核心目标是在无监督条件下学习真实数据分布，并从随机噪声中生成与真实数据难以区分的样本。在迭代训练过程中，生成器持续优化生成样本的质量以欺骗判别器，判别器则不断提升鉴别真伪的能力，二者形成动态博弈关系直至达到均衡。这一独特的迭代优化过程使生成器的输出分布逐渐逼近真实数据分布，同时推动判别器的判别能力同步增强。

在此基础上，大量工作进一步探索了GAN在图像质量提升领域中的潜力，并将其成功应用于超分辨率重建、图像去噪、去模糊以及低光照图像增强等典型任务中。Ledig\cite{ledig2017photo} 等人提出SRGAN，旨在解决传统超分辨率方法在大倍率放大条件下难以有效恢复高频纹理细节的问题。该研究首次将生成对抗网络引入单图像超分辨率任务，通过引入对抗损失约束，引导生成结果向自然图像流形靠拢，从而提升重建图像的感知质量。SRGAN由一个深度残差生成网络和一个判别网络构成，其中生成器负责从低分辨率图像中重建高分辨率图像，判别器则用于区分生成图像与真实高分辨率图像。与此同时，本文提出了一种感知损失函数，该损失由基于 VGG网络高层特征的内容损失与对抗损失共同组成，用以替代传统基于像素级误差的优化目标。实验结果表明，该方法在视觉质量和主观评价（MOS）指标上显著优于以MSE为优化目标的超分辨率方法，能够生成更加逼真、具有丰富纹理细节的高分辨率图像。Kupyn\cite{kupyn2018deblurgan}等人提出了DeblurGAN，一种基于条件生成对抗网络的端到端单幅图像盲运动去模糊方法，旨在解决传统去模糊算法依赖显式模糊核建模、计算复杂且难以处理复杂真实场景模糊的问题。该研究将运动去模糊任务建模为一种特殊的图像到图像映射问题，直接学习从模糊图像到清晰图像的映射关系。DeblurGAN 采用条件 GAN 结构，其中生成器以模糊图像作为输入，输出对应的清晰图像，判别器则用于判断生成结果与真实清晰图像之间的差异。为提升训练稳定性与感知质量，作者引入了基于Wasserstein GAN的对抗损失，并结合基于VGG特征的感知损失，从而在保持全局结构一致性的同时有效恢复细节纹理。与仅使用像素级损失的去模糊方法相比，DeblurGAN能够生成更加清晰且视觉上更具真实感的结果，该方法在结构相似性和主观视觉质量方面达到或超过当时的先进水平，并且在推理速度上显著优于多尺度卷积网络方法。

CycleGAN等\cite{zhu2017unpaired}无监督图像到图像翻译方法的提出，进一步拓展了GAN在图像质量提升领域的应用范围，使得在缺乏成对训练数据的情况下也能实现高质量的图像转换。该方法通过引入循环一致性损失，确保了从源域到目标域的映射以及反向映射的一致性，从而在无监督条件下实现了有效的图像风格转换和质量提升。CycleGAN由两个生成器和两个判别器组成，其中每个生成器负责一个方向的映射，判别器则用于区分生成图像与真实图像。通过同时优化对抗损失和循环一致性损失，CycleGAN能够在保持内容结构不变的前提下，实现不同风格或质量水平之间的转换。该方法在多个图像翻译任务中表现出色，如照片到艺术画作、白天到夜晚等，并且在没有成对数据的情况下实现了高质量的图像转换，为实际应用中的数据获取问题提供了有效解决方案。

\section{原子级高分辨图像原子定位算法概述}
电镜实验在获取和分析原子级结构时面临速度慢、数据少等问题，且数据往往缺乏代表性。随着新型CCD相机的出现和数据储存速度的提升，电镜实验产生的数据量急剧增加，如何从海量数据中自动化提取细粒度信息成为主要挑战。原子定位是晶体或分子结构解析的前置任务。传统的规则化方法对图像噪声较为敏感，且依赖人工调参或后期修正，难以满足大规模自动化分析需求。深度学习模型通过自动提取图像特征，具有更好的鲁棒性，能够在低对比度和高噪声的条件下输出可用结果。

\subsection{基于规则化方法的原子定位方法}
由于人工及技术水平，通过电镜实验获取和分析原子级结构时存在速度慢、数据少等问题，考虑到宏观尺度下的微观差异，获得的数据往往不具有代表性。如果加上时间尺度以及其他测量信息，由于数据储存速度和储存量的不断提升，电镜实验获得的数据量会变得非常大。因此，如何更好更快地从海量数据中提取有效信息是目前电镜实验的实验处理阶段面临的首要问题，计算机-电子显微术-材料科学的结合应运而生。传统的高分辨透射电子显微镜原子位置识别方法已被广泛应用，并取得显著进展。

Galindo等[64]人早在2007年便在寻找峰值方法（PF）和几何相位方法（GP）的基础上提出了峰值对算法（PP），并对该方法的具体流程进行了阐述。首先用布拉格滤波或维纳滤波对HRTEM图像进行降噪处理，之后通过灰度水平进行峰值定位，搜索具有相对距离和方向的两组峰值对，就可以依据此计算位移场。这个方法不仅可以应用于HRTEM图像，也可以应用于任何类型的晶格图像，如高分辨率Z衬度像。

2016年，Zhang等[63]改进了几何相位分析（GPA）。原先的几何相位分析方法是采用快速傅里叶变换的传统GPA方法，即全局GPA（G-GPA），是基于位移和相位差之间的关系。改进以后的方法是在图像中逐块进行窗口式傅里叶变换，称为子集GPA（S-GPA）。在计算小应变（小于2000με）时，S-GPA的测量精度比G-GPA高出3倍左右。对于大应变（大于15 με万），S-GPA的测量精度比G-GPA高出约50\%。此外，S-GPA方法可以显著消除相填充效应，而G-GPA方法不能。Zhang等人用该方法成功分析了InGaAs/InAlAs超晶格异质结构中的应变场分布。

在之后的研究中，Wen等[62]将子集相位分析（S-GPA）与寻峰方法（PF）和最优逼近算法（OAA）相结合，可以同时准确地确定多个界面层中的所有原子。在确定界面位置的基础上，通过优化选择多个参考区域，同时测量了超晶格结构各层的应变分布。该方法成功地应用于评价分子束外延生长的In0.6Ga0.4As/In0.44Al0.56As 超晶格结构的晶格质量。结果表明：界面晶格几乎完美，层厚均匀，没有缺陷和应力集中。

Zhang等[59]在2018年提出了多椭圆拟合方法。如图5a，该方法首先将灰度图立体化，以色谱柱的形式表现，利用原子柱周围的一系列等距强度水平的等高线，将其拟合为一系列椭圆，即通过椭圆旋转平均得到原子位置信息，在此基础上还可以计算出各原子列的强度分布。此外，原子柱的位置可以通过减去相邻原子柱的强度来细化图像，这种方法可以将原子列的位置精确到皮米范围内。Zhang等人通过测量和模拟SrTiO3的高分辨透射电镜图像，定量的得到了预期精度。

此外，自动化的图像处理软件工具如CalAtom(图5b)和Atomap(图5c)的开发，也推动了自动化分析原子分辨率图像的进程。Magnus Nord[61]研发的Atomap软件，利用基于模型的2D-高斯分布自动量化原子分辨率STEM图像中原子列的位置和形状，在钙钛矿氧化物异质结构的 HAADF和ABF STEM图像上进行了测试，定量分析ABF图像中氧原子柱的位移。Q. Zhang[60]在 MATLAB™中开发了CalAtom的软件工具，用于(扫描)透射电子显微镜图像中的原子柱定量分析。该软件提供了三种高精度确定原子柱位置的算法:矩量法、基于模型的方法和多椭圆拟合方法。基于测量位置，该软件为进一步分析提供了几个选项，如原子柱的平面尺度局部环境，局部初等组成和图像图案的实空间平均。以MoS2(1−x)Se2x单分子层的HAADF-STEM实验图像为例，首先利用MEF方法确定原子柱的位置。原子柱的伪彩色显示直观地说明了原子柱的形状和中心;通过计算每个原子列的平均强度，可以得到一个局部元素图。在映射计算中，利用原子的相对位置（原子列）来区分Mo和X2位点，特别是采用均值位移聚类法的无监督分类算法，在X2位点上实现了适当的元素分类，揭示了Se原子主要沿MoS2单分子层的晶界掺杂。这些工具减少了手动干预的需求，使得研究者可以更高效地处理大量原子级图像数据，从而大大提高了分析效率和准确性。



 
\subsection{基于深度学习方法的原子定位方法}
基于深度学习的方法能够进一步提升原子定位的准确率，提升大规模图像数据处理的效率和一致性。在此基础上，能够识别复杂材料中的缺陷和局部结构变化，并将图像分析结果与材料的物理和化学特性关联起来。表1按照不同训练策略对原子定位的深度学习方法进行分类。分析发现，大多工作基于监督学习展开，在模拟数据上训练、实验数据上测试。

\begin{figure} [H]
    \centering
    \includegraphics[width=0.8\textwidth]{images/chap2/unet.png}
    \bicaption{U-Net网络模型架构示意图}{U-Net network model architecture diagram}
    \label{fig:unet}
\end{figure}

\section{性能评价指标概述}


\section{本章小结}